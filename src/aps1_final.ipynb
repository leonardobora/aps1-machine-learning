{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Previsão de Emissões de N2O no Brasil\n",
    "\n",
    "Este notebook apresenta um modelo otimizado para previsão de emissões de óxido nitroso (N2O) no Brasil,\n",
    "com foco em superar o baseline simplista fornecido pelo professor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compreensão e Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Carrega os dados do arquivo CSV e retorna um DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Caminho para o arquivo CSV.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame pandas com os dados carregados.\n",
    "    \"\"\"\n",
    "    print(f\"Carregando dados de {file_path}...\")\n",
    "    return pd.read_csv(file_path, encoding='utf-8')\n",
    "\n",
    "\n",
    "def explore_data(data):\n",
    "    \"\"\"\n",
    "    Explora os dados e exibe estatísticas básicas.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame pandas para exploração.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== EXPLORAÇÃO INICIAL DOS DADOS ===\")\n",
    "    \n",
    "    # Verificar as primeiras linhas do dataset\n",
    "    print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Informações das colunas\n",
    "    print(\"\\nColunas disponíveis:\", data.columns.tolist())\n",
    "    print(f\"Número total de registros: {len(data)}\")\n",
    "    \n",
    "    # Resumo estatístico\n",
    "    print(\"\\nInformações gerais do dataset:\")\n",
    "    print(data.info())\n",
    "    \n",
    "    # Resumo estatístico das colunas numéricas\n",
    "    print(\"\\nResumo estatístico das colunas numéricas:\")\n",
    "    print(data.describe())\n",
    "    \n",
    "    # Verificar valores nulos\n",
    "    missing_values = data.isnull().sum()\n",
    "    print(\"\\nValores nulos por coluna:\")\n",
    "    print(missing_values)\n",
    "    \n",
    "    # Porcentagem de valores nulos\n",
    "    missing_percentage = (missing_values / len(data)) * 100\n",
    "    print(\"\\nPorcentagem de valores nulos por coluna:\")\n",
    "    for col, pct in missing_percentage.items():\n",
    "        if pct > 0:\n",
    "            print(f\"{col}: {pct:.2f}%\")\n",
    "\n",
    "\n",
    "def filter_gas_data(data, gas_name):\n",
    "    \"\"\"\n",
    "    Filtra os dados para um gás específico e exibe informações sobre o subconjunto.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame pandas com todos os dados.\n",
    "        gas_name: Nome do gás para filtragem.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame pandas contendo apenas os dados do gás especificado.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== FILTRANDO DADOS DE {gas_name} ===\")\n",
    "    filtered_data = data[data['gas'].str.contains(gas_name, case=False, na=False)]\n",
    "    \n",
    "    print(f\"Registros de {gas_name}: {len(filtered_data)}\")\n",
    "    print(\"\\nResumo estatístico:\")\n",
    "    print(filtered_data.describe())\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "# Carregar dados\n",
    "data_path = \"../data/br_seeg_emissoes_brasil.csv\"\n",
    "data = load_data(data_path)\n",
    "\n",
    "# Explorar dados\n",
    "explore_data(data)\n",
    "\n",
    "# Filtrar dados de N2O\n",
    "n2o_data = filter_gas_data(data, 'N2O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Exploratória (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emissions_by_year(data, gas_name):\n",
    "    \"\"\"\n",
    "    Gera um gráfico de linha mostrando emissões por ano.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame com os dados filtrados.\n",
    "        gas_name: Nome do gás para o título.\n",
    "    \"\"\"\n",
    "    emissions_by_year = data.groupby('ano')['emissao'].sum().reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(emissions_by_year['ano'], emissions_by_year['emissao'], marker='o', linewidth=2)\n",
    "    plt.title(f'Emissões Totais de {gas_name} por Ano', fontsize=14)\n",
    "    plt.xlabel('Ano', fontsize=12)\n",
    "    plt.ylabel('Emissão Total (t)', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    # Adicionar anotações para eventos importantes\n",
    "    plt.annotate('Salto em 1990', xy=(1990, 500000), xytext=(1987, 300000),\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_emissions_by_sector(data, gas_name):\n",
    "    \"\"\"\n",
    "    Gera um gráfico de barras mostrando emissões por setor.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame com os dados filtrados.\n",
    "        gas_name: Nome do gás para o título.\n",
    "    \"\"\"\n",
    "    emissions_by_sector = data.groupby('nivel_1')['emissao'].sum().sort_values(ascending=False).reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    bar_plot = sns.barplot(data=emissions_by_sector, x='nivel_1', y='emissao')\n",
    "    \n",
    "    # Adicionar rótulos com os valores percentuais\n",
    "    total = emissions_by_sector['emissao'].sum()\n",
    "    for i, p in enumerate(bar_plot.patches):\n",
    "        percentage = 100 * p.get_height() / total\n",
    "        bar_plot.annotate(f'{percentage:.1f}%',\n",
    "                          (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                          ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.title(f'Emissões de {gas_name} por Setor', fontsize=14)\n",
    "    plt.xlabel('Setor', fontsize=12)\n",
    "    plt.ylabel('Emissão Total (t)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_emission_distribution(data, gas_name):\n",
    "    \"\"\"\n",
    "    Gera gráficos para visualizar a distribuição das emissões.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame com os dados filtrados.\n",
    "        gas_name: Nome do gás para o título.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Histograma da distribuição original (log scale)\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(data['emissao'][data['emissao'] > 0], bins=50, log=True)\n",
    "    plt.title(f'Distribuição das Emissões de {gas_name} (Log Scale)', fontsize=12)\n",
    "    plt.xlabel('Emissão (t)', fontsize=10)\n",
    "    plt.ylabel('Frequência (log)', fontsize=10)\n",
    "    \n",
    "    # Boxplot por nível hierárquico 1\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.boxplot(data=data, x='nivel_1', y='emissao')\n",
    "    plt.title(f'Boxplot de Emissões de {gas_name} por Setor', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Boxplot por ano (agrupado)\n",
    "    years_to_show = list(range(1970, 2020, 10))\n",
    "    plt.subplot(2, 2, 3)\n",
    "    year_data = data[data['ano'].isin(years_to_show)]\n",
    "    sns.boxplot(data=year_data, x='ano', y='emissao')\n",
    "    plt.title(f'Boxplot de Emissões de {gas_name} por Década', fontsize=12)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Scatterplot ano vs emissão (com alta transparência)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.scatter(data['ano'], data['emissao'], alpha=0.1, s=10)\n",
    "    plt.title(f'Dispersão de Emissões de {gas_name} por Ano', fontsize=12)\n",
    "    plt.xlabel('Ano', fontsize=10)\n",
    "    plt.ylabel('Emissão (t)', fontsize=10)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plotar análises\n",
    "plot_emissions_by_year(n2o_data, 'N2O')\n",
    "plot_emissions_by_sector(n2o_data, 'N2O')\n",
    "plot_emission_distribution(n2o_data, 'N2O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tratamento de Dados e Engenharia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(data):\n",
    "    \"\"\"\n",
    "    Trata valores ausentes nos dados.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame a ser processado.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com valores ausentes tratados.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== TRATAMENTO DE VALORES AUSENTES ===\")\n",
    "    \n",
    "    # Copiar dados para não modificar o original\n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # Verificar valores nulos originais\n",
    "    null_before = processed_data.isnull().sum()\n",
    "    null_pct_before = (null_before / len(processed_data)) * 100\n",
    "    \n",
    "    # Preencher valores ausentes em colunas categóricas com \"Desconhecido\"\n",
    "    cat_columns = processed_data.select_dtypes(include=['object']).columns\n",
    "    for col in cat_columns:\n",
    "        if null_before[col] > 0:\n",
    "            processed_data[col].fillna('Desconhecido', inplace=True)\n",
    "    \n",
    "    # Preencher valores ausentes em 'emissao' com 0\n",
    "    if 'emissao' in processed_data.columns and null_before['emissao'] > 0:\n",
    "        processed_data['emissao'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Verificar valores nulos após processamento\n",
    "    null_after = processed_data.isnull().sum()\n",
    "    \n",
    "    # Mostrar resumo do tratamento\n",
    "    print(\"Colunas tratadas para valores ausentes:\")\n",
    "    for col in null_before.index:\n",
    "        if null_before[col] > 0:\n",
    "            print(f\"  {col}: {null_before[col]} valores ausentes ({null_pct_before[col]:.2f}%) → {null_after[col]} restantes\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def handle_outliers(data, column, method='iqr', threshold=1.5):\n",
    "    \"\"\"\n",
    "    Detecta e trata outliers em uma coluna específica.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame contendo os dados.\n",
    "        column: Nome da coluna a ser tratada.\n",
    "        method: Método para detecção de outliers ('iqr' ou 'zscore').\n",
    "        threshold: Limite para considerar um valor como outlier.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com outliers tratados.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== TRATAMENTO DE OUTLIERS NA COLUNA '{column}' ===\")\n",
    "    \n",
    "    # Copiar dados para não modificar o original\n",
    "    processed_data = data.copy()\n",
    "    original_count = len(processed_data)\n",
    "    \n",
    "    if method.lower() == 'iqr':\n",
    "        # Método IQR (Interquartile Range)\n",
    "        Q1 = processed_data[column].quantile(0.25)\n",
    "        Q3 = processed_data[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        \n",
    "        print(f\"Limites calculados pelo método IQR:\")\n",
    "        print(f\"  Q1 = {Q1:.2f}\")\n",
    "        print(f\"  Q3 = {Q3:.2f}\")\n",
    "        print(f\"  IQR = {IQR:.2f}\")\n",
    "        print(f\"  Limite inferior = {lower_bound:.2f}\")\n",
    "        print(f\"  Limite superior = {upper_bound:.2f}\")\n",
    "        \n",
    "        # Identificar outliers\n",
    "        outliers = processed_data[(processed_data[column] < lower_bound) | \n",
    "                                 (processed_data[column] > upper_bound)]\n",
    "        \n",
    "        # Tratar outliers (substituir por limites)\n",
    "        processed_data.loc[processed_data[column] > upper_bound, column] = upper_bound\n",
    "        processed_data.loc[processed_data[column] < lower_bound, column] = lower_bound\n",
    "        \n",
    "    elif method.lower() == 'zscore':\n",
    "        # Método Z-score\n",
    "        from scipy import stats\n",
    "        z_scores = stats.zscore(processed_data[column])\n",
    "        abs_z_scores = np.abs(z_scores)\n",
    "        outliers = processed_data[abs_z_scores > threshold]\n",
    "        \n",
    "        # Tratar outliers (substituir por limite do z-score)\n",
    "        mean_val = processed_data[column].mean()\n",
    "        std_val = processed_data[column].std()\n",
    "        upper_bound = mean_val + threshold * std_val\n",
    "        lower_bound = mean_val - threshold * std_val\n",
    "        \n",
    "        print(f\"Limites calculados pelo método Z-score:\")\n",
    "        print(f\"  Média = {mean_val:.2f}\")\n",
    "        print(f\"  Desvio padrão = {std_val:.2f}\")\n",
    "        print(f\"  Limite inferior = {lower_bound:.2f}\")\n",
    "        print(f\"  Limite superior = {upper_bound:.2f}\")\n",
    "        \n",
    "        processed_data.loc[processed_data[column] > upper_bound, column] = upper_bound\n",
    "        processed_data.loc[processed_data[column] < lower_bound, column] = lower_bound\n",
    "    \n",
    "    # Resumo do tratamento\n",
    "    print(f\"Outliers detectados: {len(outliers)} ({len(outliers)/original_count*100:.2f}% dos dados)\")\n",
    "    print(f\"  Média antes do tratamento: {data[column].mean():.2f}\")\n",
    "    print(f\"  Média após tratamento: {processed_data[column].mean():.2f}\")\n",
    "    print(f\"  Mediana antes: {data[column].median():.2f}\")\n",
    "    print(f\"  Mediana após: {processed_data[column].median():.2f}\")\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def create_features(data):\n",
    "    \"\"\"\n",
    "    Cria novas features a partir das existentes.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame com os dados originais.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com as novas features adicionadas.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== ENGENHARIA DE FEATURES ===\")\n",
    "    \n",
    "    # Copiar dados para não modificar o original\n",
    "    enhanced_data = data.copy()\n",
    "    \n",
    "    # 1. Features temporais: década\n",
    "    enhanced_data['decada'] = (enhanced_data['ano'] // 10) * 10\n",
    "    \n",
    "    # 2. Feature para identificar se a emissão está relacionada à agropecuária\n",
    "    enhanced_data['is_agropecuaria'] = (enhanced_data['nivel_1'] == 'Agropecuária').astype(int)\n",
    "    \n",
    "    # 3. Features para combinações importantes de níveis hierárquicos\n",
    "    enhanced_data['nivel_1_2'] = enhanced_data['nivel_1'] + '_' + enhanced_data['nivel_2']\n",
    "    \n",
    "    # 4. Feature para identificar tipo de emissão (simplificação)\n",
    "    if 'tipo_emissao' in enhanced_data.columns:\n",
    "        emission_type_map = {'Emissão': 1, 'Remoção': -1}\n",
    "        enhanced_data['emission_factor'] = enhanced_data['tipo_emissao'].map(emission_type_map).fillna(0)\n",
    "    \n",
    "    # 5. Transformação logarítmica para valores positivos de emissão (ajuda a lidar com dados enviesados)\n",
    "    enhanced_data['log_emissao'] = np.log1p(enhanced_data['emissao'].clip(lower=0))\n",
    "    \n",
    "    # Resumo das novas features\n",
    "    print(\"Novas features criadas:\")\n",
    "    new_features = ['decada', 'is_agropecuaria', 'nivel_1_2', 'emission_factor', 'log_emissao']\n",
    "    for col in new_features:\n",
    "        if col in enhanced_data.columns:\n",
    "            print(f\"  - {col}\")\n",
    "    \n",
    "    print(f\"\\nDimensões dos dados: {enhanced_data.shape[0]} linhas x {enhanced_data.shape[1]} colunas\")\n",
    "    \n",
    "    return enhanced_data\n",
    "\n",
    "\n",
    "# Tratar valores ausentes\n",
    "n2o_data_processed = handle_missing_values(n2o_data)\n",
    "\n",
    "# Tratar outliers na coluna de emissão\n",
    "n2o_data_processed = handle_outliers(n2o_data_processed, 'emissao', method='iqr', threshold=3.0)\n",
    "\n",
    "# Criar novas features\n",
    "n2o_data_enhanced = create_features(n2o_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparação para Modelagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_modeling(data, features, target, train_years, test_years):\n",
    "    \"\"\"\n",
    "    Prepara os dados para modelagem, incluindo one-hot encoding e divisão de treino/teste.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame com os dados filtrados.\n",
    "        features: Lista de colunas a serem usadas como features.\n",
    "        target: Nome da coluna alvo.\n",
    "        train_years: Range de anos para o conjunto de treino.\n",
    "        test_years: Range de anos para o conjunto de teste.\n",
    "        \n",
    "    Returns:\n",
    "        X_train, y_train, X_test, y_test para modelagem.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== PREPARAÇÃO PARA MODELAGEM ===\")\n",
    "    print(f\"Features selecionadas: {features}\")\n",
    "    print(f\"Target: {target}\")\n",
    "    print(f\"Anos de treino: {min(train_years)}-{max(train_years)}\")\n",
    "    print(f\"Anos de teste: {min(test_years)}-{max(test_years)}\")\n",
    "    \n",
    "    # One-hot encoding para variáveis categóricas\n",
    "    categorical_features = [col for col in features if col != 'ano' and data[col].dtype == 'object']\n",
    "    print(f\"Features categóricas a serem codificadas: {categorical_features}\")\n",
    "    \n",
    "    data_encoded = pd.get_dummies(data[features + [target]],\n",
    "                                  columns=categorical_features)\n",
    "    \n",
    "    print(f\"Dimensões após one-hot encoding: {data_encoded.shape[0]} linhas x {data_encoded.shape[1]} colunas\")\n",
    "    \n",
    "    # Divisão temporal\n",
    "    X_train = data_encoded[data_encoded['ano'].isin(train_years)].drop(columns=[target])\n",
    "    y_train = data_encoded[data_encoded['ano'].isin(train_years)][target]\n",
    "    X_test = data_encoded[data_encoded['ano'].isin(test_years)].drop(columns=[target])\n",
    "    y_test = data_encoded[data_encoded['ano'].isin(test_years)][target]\n",
    "    \n",
    "    print(f\"Conjuntos de dados:\")\n",
    "    print(f\"  X_train: {X_train.shape[0]} linhas x {X_train.shape[1]} colunas\")\n",
    "    print(f\"  y_train: {y_train.shape[0]} valores\")\n",
    "    print(f\"  X_test: {X_test.shape[0]} linhas x {X_test.shape[1]} colunas\")\n",
    "    print(f\"  y_test: {y_test.shape[0]} valores\")\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "def impute_missing_values(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Imputa valores ausentes nos dados de treino e teste.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test, y_train, y_test: Dados para imputação.\n",
    "        \n",
    "    Returns:\n",
    "        Dados com valores ausentes imputados.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== IMPUTAÇÃO DE VALORES AUSENTES ===\")\n",
    "    print(f\"Valores NaN antes da imputação:\")\n",
    "    print(f\"  X_train: {X_train.isnull().sum().sum()}\")\n",
    "    print(f\"  X_test: {X_test.isnull().sum().sum()}\")\n",
    "    print(f\"  y_train: {y_train.isnull().sum()}\")\n",
    "    print(f\"  y_test: {y_test.isnull().sum()}\")\n",
    "    \n",
    "    # Aplicar SimpleImputer para preencher valores ausentes nos dados de entrada\n",
    "    if X_train.isnull().sum().sum() > 0 or X_test.isnull().sum().sum() > 0:\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "        X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "    else:\n",
    "        X_train_imputed = X_train.copy()\n",
    "        X_test_imputed = X_test.copy()\n",
    "    \n",
    "    # Aplicar SimpleImputer para preencher valores ausentes nos dados de saída\n",
    "    if y_train.isnull().sum() > 0 or y_test.isnull().sum() > 0:\n",
    "        y_imputer = SimpleImputer(strategy=\"mean\")\n",
    "        y_train_imputed = pd.Series(\n",
    "            y_imputer.fit_transform(y_train.values.reshape(-1, 1)).flatten(), \n",
    "            index=y_train.index\n",
    "        )\n",
    "        y_test_imputed = pd.Series(\n",
    "            y_imputer.transform(y_test.values.reshape(-1, 1)).flatten(), \n",
    "            index=y_test.index\n",
    "        )\n",
    "    else:\n",
    "        y_train_imputed = y_train.copy()\n",
    "        y_test_imputed = y_test.copy()\n",
    "    \n",
    "    print(f\"Valores NaN após imputação:\")\n",
    "    print(f\"  X_train: {X_train_imputed.isnull().sum().sum()}\")\n",
    "    print(f\"  X_test: {X_test_imputed.isnull().sum().sum()}\")\n",
    "    print(f\"  y_train: {y_train_imputed.isnull().sum()}\")\n",
    "    print(f\"  y_test: {y_test_imputed.isnull().sum()}\")\n",
    "    \n",
    "    return X_train_imputed, X_test_imputed, y_train_imputed, y_test_imputed\n",
    "\n",
    "\n",
    "def normalize_features(X_train, X_test, method='standard'):\n",
    "    \"\"\"\n",
    "    Normaliza as features para melhorar o desempenho do modelo.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Features de treino.\n",
    "        X_test: Features de teste.\n",
    "        method: Método de normalização ('standard' ou 'minmax').\n",
    "        \n",
    "    Returns:\n",
    "        Features normalizadas.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== NORMALIZAÇÃO DE FEATURES ({method.upper()}) ===\")\n",
    "    \n",
    "    if method.lower() == 'standard':\n",
    "        # Padronização (Z-score)\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        # Normalização Min-Max\n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    # Identificar colunas numéricas\n",
    "    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    print(f\"Colunas numéricas a serem normalizadas: {numeric_cols}\")\n",
    "    \n",
    "    # Aplicar normalização apenas às colunas numéricas\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    \n",
    "    # Verificar se há colunas numéricas para serem normalizadas\n",
    "    if numeric_cols:\n",
    "        X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "        X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "    \n",
    "    print(\"Normalização concluída.\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "\n",
    "def select_best_features(X_train, y_train, X_test, k=20):\n",
    "    \"\"\"\n",
    "    Seleciona as k melhores features com base na correlação com o target.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Features de treino.\n",
    "        y_train: Target de treino.\n",
    "        X_test: Features de teste.\n",
    "        k: Número de features a selecionar.\n",
    "        \n",
    "    Returns:\n",
    "        X_train e X_test com apenas as k melhores features.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== SELEÇÃO DAS {k} MELHORES FEATURES ===\")\n",
    "    \n",
    "    # Ajustar k se for maior que o número de colunas disponíveis\n",
    "    k = min(k, X_train.shape[1])\n",
    "    \n",
    "    # Selecionar as k melhores features\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Obter os índices das features selecionadas\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    selected_features = X_train.columns[selected_indices].tolist()\n",
    "    \n",
    "    print(f\"Features selecionadas: {selected_features}\")\n",
    "    \n",
    "    # Retornar apenas as colunas selecionadas\n",
    "    return X_train[selected_features], X_test[selected_features]\n",
    "\n",
    "\n",
    "# Selecionar features (incluindo as novas features criadas)\n",
    "features = [\n",
    "    'ano', 'nivel_1', 'nivel_2', 'nivel_3', 'nivel_4', 'nivel_5', 'nivel_6',\n",
    "    'decada', 'is_agropecuaria', 'nivel_1_2', 'log_emissao'\n",
    "]\n",
    "target = 'emissao'\n",
    "\n",
    "# Definir períodos de treino e teste (80% treino, 20% teste)\n",
    "train_years = range(1970, 2016)  # 46 anos (80%)\n",
    "test_years = range(2016, 2020)   # 4 anos (20%) - indo até 2019 pois 2020 pode estar incompleto\n",
    "\n",
    "# Preparar dados para modelagem\n",
    "X_train, y_train, X_test, y_test = prepare_data_for_modeling(\n",
    "    n2o_data_enhanced, features, target, train_years, test_years\n",
    ")\n",
    "\n",
    "# Imputar valores ausentes\n",
    "X_train, X_test, y_train, y_test = impute_missing_values(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Normalizar features\n",
    "X_train_scaled, X_test_scaled = normalize_features(X_train, X_test, method='standard')\n",
    "\n",
    "# Selecionar as melhores features\n",
    "X_train_best, X_test_best = select_best_features(X_train_scaled, y_train, X_test_scaled, k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelagem e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Avalia o desempenho de um modelo usando várias métricas.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Valores verdadeiros.\n",
    "        y_pred: Valores previstos.\n",
    "        model_name: Nome do modelo para exibição.\n",
    "        \n",
    "    Returns:\n",
    "        Dicionário com as métricas calculadas.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "    print(f\"  R²: {r2:.2f}\")\n",
    "    \n",
    "    return {'model': model_name, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Treina e avalia múltiplos modelos de regressão.\n",
    "    \n",
    "    Args:\n",
    "        X_train, y_train: Dados de treino.\n",
    "        X_test, y_test: Dados de teste.\n",
    "        \n",
    "    Returns:\n",
    "        Lista com os resultados de avaliação para todos os modelos.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== TREINAMENTO E AVALIAÇÃO DE MODELOS ===\")\n",
    "    results = []\n",
    "    models = {}\n",
    "    \n",
    "    # Modelo baseline: Regressão Linear\n",
    "    print(\"\\n1. Treinando Regressão Linear (baseline)...\")\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    lr_pred = lr_model.predict(X_test)\n",
    "    results.append(evaluate_model(y_test, lr_pred, \"Regressão Linear\"))\n",
    "    models[\"Regressão Linear\"] = lr_model\n",
    "    \n",
    "    # Árvore de Decisão\n",
    "    print(\"\\n2. Treinando Árvore de Decisão...\")\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "    results.append(evaluate_model(y_test, dt_pred, \"Árvore de Decisão\"))\n",
    "    models[\"Árvore de Decisão\"] = dt_model\n",
    "    \n",
    "    # Random Forest com hiperparâmetros fixos\n",
    "    print(\"\\n3. Treinando Random Forest (hiperparâmetros padrão)...\")\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_pred = rf_model.predict(X_test)\n",
    "    results.append(evaluate_model(y_test, rf_pred, \"Random Forest (padrão)\"))\n",
    "    models[\"Random Forest (padrão)\"] = rf_model\n",
    "    \n",
    "    # Random Forest com otimização de hiperparâmetros\n",
    "    print(\"\\n4. Otimizando Random Forest com GridSearchCV...\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Exibir melhores hiperparâmetros encontrados\n",
    "    print(f\"Melhores hiperparâmetros para Random Forest: {grid_search.best_params_}\")\n",
    "    \n",
    "    best_rf = grid_search.best_estimator_\n",
    "    rf_opt_pred = best_rf.predict(X_test)\n",
    "    results.append(evaluate_model(y_test, rf_opt_pred, \"Random Forest (otimizado)\"))\n",
    "    models[\"Random Forest (otimizado)\"] = best_rf\n",
    "    \n",
    "    # Gradient Boosting\n",
    "    print(\"\\n5. Treinando Gradient Boosting...\")\n",
    "    gb_model = GradientBoostingRegressor(random_state=42)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    gb_pred = gb_model.predict(X_test)\n",
    "    results.append(evaluate_model(y_test, gb_pred, \"Gradient Boosting\"))\n",
    "    models[\"Gradient Boosting\"] = gb_model\n",
    "    \n",
    "    # Exibir feature importances do melhor modelo (Random Forest otimizado)\n",
    "    if isinstance(best_rf, RandomForestRegressor):\n",
    "        print(\"\\nImportância das features (Random Forest otimizado):\")\n",
    "        feature_importances = pd.DataFrame({\n",
    "            'Feature': X_train.columns,\n",
    "            'Importance': best_rf.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        print(feature_importances.head(10))\n",
    "    \n",
    "    # Identificar o melhor modelo\n",
    "    best_r2_idx = max(range(len(results)), key=lambda i: results[i]['r2'])\n",
    "    best_model_name = results[best_r2_idx]['model']\n",
    "    best_model = models[best_model_name]\n",
    "    \n",
    "    print(f\"\\nO melhor modelo baseado em R² é: {best_model_name}\")\n",
    "    \n",
    "    return results, best_model\n",
    "\n",
    "\n",
    "def visualize_model_comparison(results):\n",
    "    \"\"\"\n",
    "    Visualiza a comparação entre os modelos testados.\n",
    "    \n",
    "    Args:\n",
    "        results: Lista de dicionários com os resultados de avaliação.\n",
    "    \"\"\"\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Organizar para o gráfico\n",
    "    metrics = ['rmse', 'mae', 'r2']\n",
    "    models = results_df['model'].tolist()\n",
    "    \n",
    "    # Gráfico de barras para cada métrica\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        bars = plt.bar(models, results_df[metric], color=sns.color_palette(\"viridis\", len(models)))\n",
    "        \n",
    "        # Adicionar rótulos com os valores\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + (max(results_df[metric])*0.01),\n",
    "                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        plt.title(f'Comparação de {metric.upper()} entre Modelos', fontsize=14)\n",
    "        plt.ylabel(metric.upper(), fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Adicionar legenda explicativa no último quadrante\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.axis('off')\n",
    "    plt.text(0.1, 0.9, 'Interpretação das Métricas:', fontsize=14, weight='bold')\n",
    "    plt.text(0.1, 0.8, '• RMSE: Erro Quadrático Médio (menor é melhor)', fontsize=12)\n",
    "    plt.text(0.1, 0.7, '• MAE: Erro Absoluto Médio (menor é melhor)', fontsize=12)\n",
    "    plt.text(0.1, 0.6, '• R²: Coeficiente de Determinação (maior é melhor)', fontsize=12)\n",
    "    plt.text(0.1, 0.4, 'Conclusão:', fontsize=14, weight='bold')\n",
    "    \n",
    "    # Identificar o melhor modelo para cada métrica\n",
    "    best_rmse = results_df.loc[results_df['rmse'].idxmin()]['model']\n",
    "    best_mae = results_df.loc[results_df['mae'].idxmin()]['model']\n",
    "    best_r2 = results_df.loc[results_df['r2'].idxmax()]['model']\n",
    "    \n",
    "    plt.text(0.1, 0.3, f'• Melhor modelo para RMSE: {best_rmse}', fontsize=12)\n",
    "    plt.text(0.1, 0.2, f'• Melhor modelo para MAE: {best_mae}', fontsize=12)\n",
    "    plt.text(0.1, 0.1, f'• Melhor modelo para R²: {best_r2}', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_predictions(y_test, predictions, model_name):\n",
    "    \"\"\"\n",
    "    Visualiza as previsões versus valores reais.\n",
    "    \n",
    "    Args:\n",
    "        y_test: Valores reais.\n",
    "        predictions: Valores previstos pelo modelo.\n",
    "        model_name: Nome do modelo para o título.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Ordenar valores para melhor visualização\n",
    "    sorted_indices = np.argsort(y_test)\n",
    "    y_test_sorted = y_test.iloc[sorted_indices]\n",
    "    pred_sorted = predictions[sorted_indices]\n",
    "    \n",
    "    # Plotar valores reais e previstos\n",
    "    plt.plot(range(len(y_test_sorted)), y_test_sorted, 'b-', label='Valores Reais', alpha=0.7)\n",
    "    plt.plot(range(len(pred_sorted)), pred_sorted, 'r-', label='Previsões', alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Valores Reais vs. Previsões ({model_name})', fontsize=14)\n",
    "    plt.xlabel('Índice da Amostra (ordenado)', fontsize=12)\n",
    "    plt.ylabel('Emissão (t)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plot de reais vs. previstos\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(y_test, predictions, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "    plt.title(f'Dispersão de Valores Reais vs. Previstos ({model_name})', fontsize=14)\n",
    "    plt.xlabel('Valores Reais', fontsize=12)\n",
    "    plt.ylabel('Valores Previstos', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Treinar e avaliar modelos\n",
    "model_results, best_model = train_and_evaluate_models(X_train_best, y_train, X_test_best, y_test)\n",
    "\n",
    "# Visualizar comparação entre modelos\n",
    "visualize_model_comparison(model_results)\n",
    "\n",
    "# Visualizar previsões do melhor modelo\n",
    "best_predictions = best_model.predict(X_test_best)\n",
    "visualize_predictions(y_test, best_predictions, \"Melhor Modelo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation e Validação Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(X, y, model, n_folds=5, time_series=False):\n",
    "    \"\"\"\n",
    "    Realiza validação cruzada do modelo, com opção para séries temporais.\n",
    "    \n",
    "    Args:\n",
    "        X: Features.\n",
    "        y: Target.\n",
    "        model: Modelo já treinado.\n",
    "        n_folds: Número de folds para CV.\n",
    "        time_series: Se True, usa TimeSeriesSplit em vez de KFold.\n",
    "    \"\"\"\n",
    "    cv_type = \"Time Series\" if time_series else \"K-Fold\"\n",
    "    print(f\"\\n=== VALIDAÇÃO CRUZADA ({cv_type}, {n_folds}-FOLD) ===\")\n",
    "    \n",
    "    # Preparar cross-validation\n",
    "    if time_series:\n",
    "        cv = TimeSeriesSplit(n_splits=n_folds)\n",
    "        print(\"Usando TimeSeriesSplit para preservar a ordem temporal dos dados\")\n",
    "    else:\n",
    "        cv = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        print(\"Usando KFold com shuffle para randomização dos dados\")\n",
    "    \n",
    "    # Métricas a calcular\n",
    "    cv_rmse = cross_val_score(model, X, y, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    cv_mae = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    cv_r2 = cross_val_score(model, X, y, cv=cv, scoring='r2', n_jobs=-1)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"Resultados da validação cruzada ({n_folds}-fold):\")\n",
    "    print(f\"  RMSE: {-cv_rmse.mean():.2f} (±{cv_rmse.std():.2f})\")\n",
    "    print(f\"  MAE: {-cv_mae.mean():.2f} (±{cv_mae.std():.2f})\")\n",
    "    print(f\"  R²: {cv_r2.mean():.2f} (±{cv_r2.std():.2f})\")\n",
    "    \n",
    "    # Visualizar distribuição dos resultados\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.boxplot(-cv_rmse)\n",
    "    plt.title('RMSE por Fold', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.boxplot(-cv_mae)\n",
    "    plt.title('MAE por Fold', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.boxplot(cv_r2)\n",
    "    plt.title('R² por Fold', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {'rmse_mean': -cv_rmse.mean(), 'rmse_std': cv_rmse.std(),\n",
    "            'mae_mean': -cv_mae.mean(), 'mae_std': cv_mae.std(),\n",
    "            'r2_mean': cv_r2.mean(), 'r2_std': cv_r2.std()}\n",
    "\n",
    "\n",
    "def create_final_predictions(model, X_test, original_data, test_years):\n",
    "    \"\"\"\n",
    "    Cria o dataset final com as previsões para entrega.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo treinado.\n",
    "        X_test: Features de teste.\n",
    "        original_data: Dataset original.\n",
    "        test_years: Anos usados para teste.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame com previsões para entrega.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== GERAÇÃO DO DATASET FINAL DE PREVISÕES ===\")\n",
    "    \n",
    "    # Gerar previsões\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Criar dataframe com índices originais\n",
    "    test_indices = original_data[original_data['ano'].isin(test_years)].index\n",
    "    \n",
    "    # Verificar se temos o mesmo número de índices e previsões\n",
    "    if len(test_indices) != len(predictions):\n",
    "        print(\"AVISO: O número de índices e previsões não corresponde.\")\n",
    "        print(f\"  Índices: {len(test_indices)}\")\n",
    "        print(f\"  Previsões: {len(predictions)}\")\n",
    "        \n",
    "        # Usar apenas os primeiros n índices que correspondem às previsões\n",
    "        test_indices = test_indices[:len(predictions)]\n",
    "    \n",
    "    # Criar dataframe final\n",
    "    final_data = original_data.loc[test_indices].copy()\n",
    "    final_data['previsao'] = predictions\n",
    "    \n",
    "    # Mostrar as primeiras linhas do dataset final\n",
    "    print(f\"Dataset final com {len(final_data)} registros e previsões:\")\n",
    "    print(final_data.head())\n",
    "    \n",
    "    # Criar diretório de saída se não existir\n",
    "    import os\n",
    "    output_dir = \"../outputs\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"Diretório criado: {output_dir}\")\n",
    "    \n",
    "    # Salvar dataset final\n",
    "    output_path = f\"{output_dir}/n2o_predictions.csv\"\n",
    "    final_data.to_csv(output_path, index=False)\n",
    "    print(f\"Dataset final salvo em: {output_path}\")\n",
    "    \n",
    "    return final_data\n",
    "\n",
    "\n",
    "# Realizar validação cruzada do melhor modelo (tradicional e série temporal)\n",
    "cv_results_regular = perform_cross_validation(X_train_best, y_train, best_model, n_folds=5, time_series=False)\n",
    "cv_results_ts = perform_cross_validation(X_train_best, y_train, best_model, n_folds=5, time_series=True)\n",
    "\n",
    "# Gerar dataset final com previsões\n",
    "final_dataset = create_final_predictions(best_model, X_test_best, n2o_data, test_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo desenvolvido para prever emissões de N2O no Brasil mostrou resultados satisfatórios, superando o baseline estabelecido. Após análise exploratória detalhada, tratamento de dados e engenharia de features, o Random Forest otimizado foi o modelo com melhor desempenho, apresentando o melhor equilíbrio entre as métricas RMSE, MAE e R².\n",
    "\n",
    "**Principais conclusões:**\n",
    "\n",
    "1. O setor de Agropecuária é o maior emissor de N2O no Brasil, respondendo por mais de 70% das emissões totais.\n",
    "2. Houve um aumento significativo nas emissões a partir de 1990, possivelmente relacionado a mudanças nas práticas agrícolas ou expansão do agronegócio.\n",
    "3. Os dados apresentaram uma distribuição bastante assimétrica, com muitos valores pequenos e poucos valores extremamente altos, o que exigiu tratamento cuidadoso de outliers.\n",
    "4. A abordagem de divisão temporal dos dados (treino com anos anteriores, teste com anos mais recentes) mostrou-se adequada para avaliar a capacidade preditiva do modelo em cenários futuros.\n",
    "5. A validação cruzada confirmou a robustez do modelo, com baixa variabilidade nas métricas entre os diferentes folds.\n",
    "6. A aplicação da validação cruzada específica para séries temporais (TimeSeriesSplit) foi importante para uma avaliação mais realista do modelo.\n",
    "\n",
    "Este modelo pode ser usado como ferramenta para auxiliar na compreensão dos fatores que influenciam as emissões de N2O e potencialmente contribuir para políticas de mitigação mais eficazes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}